{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*   目标\n",
    "将基本的 Transformer 架构进行输入转换和位置编码定制，并加入上下文信息，从而使其能够有效地处理和预测复杂的时空（Vision）数据\n",
    "\n",
    "* 实现Traffic Accident Risk Forecasting using Contextual Vision Transformers这篇论文提到的内容.我所用的数据集是预处理好的,有纽约和芝加哥两个城市,但我们先只用芝加哥这个城市.每个城市有12份文件.并且先只训练fine这个细粒度,并没有管另外六个文件(属于粗粒度)\n",
    "\n",
    "*   输入数据-分成粗糙和细腻各6个文件\n",
    "主输入是$T\\times d \\times I \\times J$   时间×维度×二维网格位置\n",
    "这是时间序列,其他都是静态信息\n",
    "\n",
    "\n",
    "---\n",
    "* **数据集**：芝加哥 (Chicago) 交通事故数据集。\n",
    "* **实验范围**：本次实验先只做于 **Fine-grained (细粒度)** 尺度的预测。\n",
    "* **输入数据**：\n",
    "    * **动态数据**：历史事故风险图（$T \\times D \\times H \\times W$）。\n",
    "    * **静态数据**：区域的固有属性（如功能区分布）和路网拓扑图(用于将数据从grid和node间转换)。\n"
   ],
   "metadata": {
    "id": "OXZFJBwIBtSi"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xKjKJhCGvMSU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307867088,
     "user_tz": -480,
     "elapsed": 7888,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:22.990781Z",
     "start_time": "2025-11-28T06:23:22.982450Z"
    }
   },
   "source": [
    "#from google.colab import drive  #用于从drive中拿数据集\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,average_precision_score\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "设立随机种子,确保结果可复现"
   ],
   "metadata": {
    "id": "GEVX4t77l3_M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                  # 固定 Python 的随机数种子\n",
    "    np.random.seed(seed)               # 固定 numpy 的随机数种子\n",
    "    torch.manual_seed(seed)            # 固定 CPU 上 torch 的随机数\n",
    "    torch.cuda.manual_seed_all(seed)   # 固定所有 GPU 上 torch 的随机数\n",
    "    torch.backends.cudnn.deterministic = True  # 让 cudnn 算子确定性 (结果可复现, 但可能变慢)\n",
    "    torch.backends.cudnn.benchmark = False     # 禁用自动选择最快算法; 若输入尺寸固定可设 True 加速\n",
    "\n",
    "set_seed(42)"
   ],
   "metadata": {
    "id": "__RE48gAmAU0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307867105,
     "user_tz": -480,
     "elapsed": 7,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.035947Z",
     "start_time": "2025-11-28T06:23:23.020785Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "id-mQN3fBmWQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "19de4beb-6501-47bb-8d5f-f66e0c618e1e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307871394,
     "user_tz": -480,
     "elapsed": 4226,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.138102Z",
     "start_time": "2025-11-28T06:23:23.105230Z"
    }
   },
   "source": [
    "# _#准备工作\n",
    "# print(\"--- 正在挂载 Google Drive ---\")\n",
    "# drive.mount('/content/drive',force_remount=True)   #挂载drive\n",
    "# print(\"------------------------------\")\n",
    "\n",
    "# #拿文件\n",
    "# CHI_path = '/content/drive/MyDrive/深度学习大作业/preprocessed_data/CHI'    #对应CHI外层文件夹\n",
    "# NYC_path='/content/drive/MyDrive/深度学习大作业/preprocessed_data/NYC'  #对应NYC外层文件夹\n",
    "\n",
    "CHI_path = 'preprocessed_data/CHI'    #对应CHI外层文件夹\n",
    "NYC_path='preprocessed_data/NYC'  #对应NYC外层文件夹\n",
    "\n",
    "print(\"CHI 路径下的内容：\")\n",
    "for item in os.listdir(CHI_path):\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nNYC 路径下的内容：\")\n",
    "# 列出 NYC_path 下的所有文件和文件夹\n",
    "for item in os.listdir(NYC_path):\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHI 路径下的内容：\n",
      "new_grid_data_c_4d.npy\n",
      "new_grid_data_f_4d.npy\n",
      "new_grid_node_map_c.npy\n",
      "new_grid_node_map_f.npy\n",
      "new_poi_adj_matrix_c.npy\n",
      "new_poi_adj_matrix_f.npy\n",
      "new_risk_adj_matrix_c.npy\n",
      "new_risk_adj_matrix_f.npy\n",
      "new_road_adj_matrix_c.npy\n",
      "new_road_adj_matrix_f.npy\n",
      "new_static_feat_c.npy\n",
      "new_static_feat_f.npy\n",
      "\n",
      "NYC 路径下的内容：\n",
      "new_grid_data_c_4d.npy\n",
      "new_grid_data_f_4d.npy\n",
      "new_grid_node_map_c.npy\n",
      "new_grid_node_map_f.npy\n",
      "new_poi_adj_matrix_c.npy\n",
      "new_poi_adj_matrix_f.npy\n",
      "new_risk_adj_matrix_c.npy\n",
      "new_risk_adj_matrix_f.npy\n",
      "new_road_adj_matrix_c.npy\n",
      "new_road_adj_matrix_f.npy\n",
      "new_static_feat_c.npy\n",
      "new_static_feat_f.npy\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试文件是否能正常读取"
   ],
   "metadata": {
    "id": "xrQIkr8rWPsm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "file_test = CHI_path+'/new_grid_data_c_4d.npy'\n",
    "data = np.load(file_test)\n",
    "print(data[0:2])\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Data type: {data.dtype}\")\n",
    "print(f\"Min value: {np.min(data)}\")\n",
    "print(f\"Max value: {np.max(data)}\")\n",
    "print(f\"Mean value: {np.mean(data)}\")\n",
    "print(f\"Standard deviation: {np.std(data)}\")"
   ],
   "metadata": {
    "collapsed": true,
    "id": "LKSWRJIPWMMX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307871812,
     "user_tz": -480,
     "elapsed": 403,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "3e17dc5c-d002-4579-a59b-8d79ff680ac0",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.350245Z",
     "start_time": "2025-11-28T06:23:23.239718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.9042566e+00 1.3195530e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.9101559e+00 4.7168821e-01]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.6526899e+00\n",
      "    1.8355560e+01 1.5210954e+01]\n",
      "   ...\n",
      "   [1.5772303e+00 5.2505651e+00 1.1159116e+01 ... 1.5672208e+03\n",
      "    4.2178220e+02 0.0000000e+00]\n",
      "   [5.1560134e-01 5.1592082e-01 1.1386479e+01 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [5.0432754e-01 5.1170057e-01 2.1531825e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.7238699e+01 1.7238699e+01]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.7238699e+01 1.7238699e+01]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.1734581e+01\n",
      "    2.1734581e+01 2.1734581e+01]\n",
      "   ...\n",
      "   [2.0124611e+01 2.0124611e+01 2.0124611e+01 ... 2.1734581e+01\n",
      "    2.1734581e+01 0.0000000e+00]\n",
      "   [2.1734581e+01 2.1734581e+01 2.1734581e+01 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [2.1734581e+01 2.1734581e+01 2.1734581e+01 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    3.8085132e+00 2.6391060e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    3.8203118e+00 9.4337642e-01]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 4.8133883e+00\n",
      "    3.1367952e+01 4.8754387e+01]\n",
      "   ...\n",
      "   [1.5935560e+00 5.2669005e+00 1.4063359e+01 ... 2.2692927e+03\n",
      "    7.6751141e+02 0.0000000e+00]\n",
      "   [1.5935062e+00 1.5944936e+00 1.4940174e+01 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 7.5050721e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.8514643e+01 1.8514643e+01]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    1.8514643e+01 1.8514643e+01]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.4819122e+01\n",
      "    2.4819122e+01 2.4819122e+01]\n",
      "   ...\n",
      "   [2.2539564e+01 2.2539564e+01 2.2539564e+01 ... 2.4819122e+01\n",
      "    2.4819122e+01 0.0000000e+00]\n",
      "   [2.4819122e+01 2.4819122e+01 2.4819122e+01 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [2.4819122e+01 2.4819122e+01 2.4819122e+01 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      "  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   ...\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]\n",
      "   [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "    0.0000000e+00 0.0000000e+00]]]]\n",
      "Data shape: (8784, 7, 10, 10)\n",
      "Data type: float32\n",
      "Min value: 0.0\n",
      "Max value: 11442.4619140625\n",
      "Mean value: 16.247020721435547\n",
      "Standard deviation: 184.7215118408203\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "有粗细两个通道  12个文件是分成6:6"
   ],
   "metadata": {
    "id": "cZNpuaPOejKO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 粗\n",
    "Coarse_File_Names = [\n",
    "    'new_grid_data_c_4d.npy',\n",
    "    'new_static_feat_c.npy',\n",
    "    'new_poi_adj_matrix_c.npy',\n",
    "    'new_road_adj_matrix_c.npy',\n",
    "    'new_risk_adj_matrix_c.npy',\n",
    "    'new_grid_node_map_c.npy'\n",
    "]\n",
    "\n",
    "# 细\n",
    "\n",
    "Fine_File_Names = [\n",
    "    'new_grid_data_f_4d.npy',\n",
    "    'new_static_feat_f.npy',\n",
    "    'new_poi_adj_matrix_f.npy',\n",
    "    'new_road_adj_matrix_f.npy',\n",
    "    'new_risk_adj_matrix_f.npy',\n",
    "    'new_grid_node_map_f.npy'\n",
    "]"
   ],
   "metadata": {
    "id": "zgKAwlLAXMI0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307871837,
     "user_tz": -480,
     "elapsed": 13,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.411399Z",
     "start_time": "2025-11-28T06:23:23.403201Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "读取粗细全部文件"
   ],
   "metadata": {
    "id": "oe68dt_0pGb9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "file_dict={}\n",
    "\n",
    "for file_name in Coarse_File_Names:\n",
    "    file_path=CHI_path+'/'+file_name\n",
    "    file_dict[file_name]=np.load(file_path)\n",
    "\n",
    "for file_name in Fine_File_Names:\n",
    "    file_path=CHI_path+'/'+file_name\n",
    "    file_dict[file_name]=np.load(file_path)"
   ],
   "metadata": {
    "collapsed": true,
    "id": "cooey80KgvjJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307872404,
     "user_tz": -480,
     "elapsed": 566,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.521180Z",
     "start_time": "2025-11-28T06:23:23.433195Z"
    }
   },
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(file_dict.keys()))"
   ],
   "metadata": {
    "id": "MF51ZzJcrTJx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307872461,
     "user_tz": -480,
     "elapsed": 4,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "8892ee9a-c80a-48a9-e55d-a2b2e455accb",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.549498Z",
     "start_time": "2025-11-28T06:23:23.542858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "先拆分数据集  时间序列 所以按时间分,shuffle随机打乱分配会让模型看到未来\n",
    "\n",
    "*   训练集:前70%\n",
    "*   验证集:中15%\n",
    "*   测试集:后15%"
   ],
   "metadata": {
    "id": "CcSli8PQ9e36"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 修改代码块 1: 数据归一化与切分 ---\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# 1. 读取原始数据\n",
    "raw_data = file_dict['new_grid_data_f_4d.npy']\n",
    "print(f'原始数据最大值: {np.max(raw_data)}')\n",
    "\n",
    "# 重要的一批,不然4w多损失玩不了了\n",
    "# 2. 关键修改: Log 归一化 (Log1p = log(x+1))\n",
    "# 不用方差,均值的原因:既保留了 0 值（无事故），又抑制了极端值的破坏力\n",
    "# 这会将 [0, 11442] 的范围压缩到 [0, 9.3] 左右，极大利于 Transformer 训练\n",
    "data_norm = np.log1p(raw_data)\n",
    "print(f'归一化后数据最大值: {np.max(data_norm)}')\n",
    "\n",
    "total_size = data_norm.shape[0]\n",
    "train_size = int(total_size * train_ratio)\n",
    "val_size = int(total_size * val_ratio)\n",
    "\n",
    "print('划分连续时间序列 (使用归一化后的数据)')\n",
    "# 训练集\n",
    "train_data = data_norm[:train_size]\n",
    "\n",
    "# 验证集\n",
    "valid_data = data_norm[train_size:train_size+val_size]\n",
    "\n",
    "# 测试集\n",
    "test_data = data_norm[train_size+val_size:]\n",
    "\n",
    "print('划分时间序列完成')\n",
    "print(f'train_data shape: {train_data.shape}')\n",
    "print(f'valid_data shape: {valid_data.shape}')\n",
    "print(f'test_data shape: {test_data.shape}')"
   ],
   "metadata": {
    "id": "iQhHu4Gw9iO3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307872966,
     "user_tz": -480,
     "elapsed": 504,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "96a50b9f-89df-42d2-d344-2a880e2abb0b",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:23.846397Z",
     "start_time": "2025-11-28T06:23:23.682938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据最大值: 11442.4619140625\n",
      "归一化后数据最大值: 9.345173835754395\n",
      "划分连续时间序列 (使用归一化后的数据)\n",
      "划分时间序列完成\n",
      "train_data shape: (6148, 7, 10, 10)\n",
      "valid_data shape: (1317, 7, 10, 10)\n",
      "test_data shape: (1319, 7, 10, 10)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "将连续时间序列切分为 X (历史输入) 和 Y (未来标签) 样本.\n",
    "---\n",
    "但是这里要考虑过去时间步和预测未来时间步\n",
    "* 看多少过去的数据,预测多久未来:可以理解成一个滑动窗口,前history_steps是X,后future_steps是Y\n",
    "* 最终切分成的x和y矩阵是多对1\n",
    "* 输入 [B, d ,H , W]\n",
    "* 输出 [B , steps ,d ,H , W]"
   ],
   "metadata": {
    "id": "l-5seYIMiXqZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#规定时间步\n",
    "history_steps = 6\n",
    "future_steps = 1\n",
    "\n",
    "def split_data_x_y(data,history_steps,future_steps):\n",
    "    length = data.shape[0]\n",
    "    X , Y = [] , []\n",
    "\n",
    "    for i in range(length - history_steps - future_steps + 1): #滑动窗口\n",
    "        X.append(data[i : i + history_steps])\n",
    "        Y.append(data[i + history_steps : i + history_steps + future_steps])\n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "print('对三个数据集分别进行切分')\n",
    "X_train,Y_train = split_data_x_y(train_data,history_steps,future_steps)\n",
    "X_valid,Y_valid = split_data_x_y(valid_data,history_steps,future_steps)\n",
    "X_test,Y_test = split_data_x_y(test_data,history_steps,future_steps)\n",
    "\n",
    "\n",
    "print('切分完成')\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'Y_train shape: {Y_train.shape}')\n",
    "print(f'X_valid shape: {X_valid.shape}')\n",
    "print(f'Y_valid shape: {Y_valid.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'Y_test shape: {Y_test.shape}')"
   ],
   "metadata": {
    "id": "Vpwja1LcilNQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307872975,
     "user_tz": -480,
     "elapsed": 22,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "3344b2dc-a6d8-4ac0-f9c4-be6786dbcbaf",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.027380Z",
     "start_time": "2025-11-28T06:23:23.866196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对三个数据集分别进行切分\n",
      "切分完成\n",
      "X_train shape: (6142, 6, 7, 10, 10)\n",
      "Y_train shape: (6142, 1, 7, 10, 10)\n",
      "X_valid shape: (1311, 6, 7, 10, 10)\n",
      "Y_valid shape: (1311, 1, 7, 10, 10)\n",
      "X_test shape: (1313, 6, 7, 10, 10)\n",
      "Y_test shape: (1313, 1, 7, 10, 10)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里的时间特征和下面模型中定义的位置编码含义不同,这里是为了实现样本之间的时间顺序,后者是单个样本内的顺序"
   ],
   "metadata": {
    "id": "w5CwgBLvLLV5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 生成真实的时间特征 ---\n",
    "\n",
    "def generate_global_time_features(time_features):  # 这里生成的是所有数据的时间特征(包含三个数据集)\n",
    "    # 这里我们假设数据是连续的小时数据 (索引 0 = 第0小时)   看了部分原数据猜的\n",
    "    indices = np.arange(time_features)   #[0,1,2,3,4,5,6,....................dataset_length-1]\n",
    "\n",
    "    # 计算小时 (0-23) 和 星期 (0-6)\n",
    "    hours = indices % 24      #\n",
    "    days = (indices // 24) % 7\n",
    "\n",
    "    # 使用 Sin/Cos 编码 (4个特征)\n",
    "    # 这是transformer中经典的位置编码,因为transformer扔掉了rnn,没有时间性了\n",
    "    time_feat = np.stack([     # stack就是说把一群东西塞成一个东西\n",
    "        np.sin(2 * np.pi * hours / 24), # Hour_Sin\n",
    "        np.cos(2 * np.pi * hours / 24), # Hour_Cos\n",
    "        np.sin(2 * np.pi * days / 7),   # Week_Sin\n",
    "        np.cos(2 * np.pi * days / 7)    # Week_Cos\n",
    "    ], axis=1)\n",
    "\n",
    "    return time_feat\n",
    "\n",
    "# 生成全局时间表 (对应原始数据的 8784 行)      # 因为每个数据就是一个时间,所以说要生成样本数量的时间特征\n",
    "global_time_features = generate_global_time_features(file_dict['new_grid_data_f_4d.npy'].shape[0])\n",
    "\n",
    "# 根据索引提取时间作为每个数据集的时间特征\n",
    "def each_dataset_time_features(start_index, data_length, history_steps):\n",
    "    X_time = []\n",
    "    # 循环次数(产生的时间特征数量)必须与 split_data_x_y 中的逻辑完全一致\n",
    "    # 每个数据集样本数量是: length - history_steps - future_steps + 1\n",
    "    epoches = data_length - history_steps - future_steps + 1\n",
    "\n",
    "    for i in range(epoches):\n",
    "        current_idx = start_index + i\n",
    "        # 取出对应的 history_steps 长度的时间特征  因为每个样本要看前面的history_steps步长\n",
    "        X_time.append(global_time_features[current_idx : current_idx + history_steps])\n",
    "\n",
    "    return np.array(X_time)\n",
    "\n",
    "print(\"正在重新生成时间特征...\")\n",
    "\n",
    "# 生成特征\n",
    "Time_train = each_dataset_time_features(0, train_data.shape[0], history_steps)\n",
    "Time_val = each_dataset_time_features(train_size, valid_data.shape[0], history_steps)\n",
    "Time_test = each_dataset_time_features(train_size + val_size, test_data.shape[0], history_steps)\n",
    "\n",
    "print(f\"Time_train shape: {Time_train.shape}\")"
   ],
   "metadata": {
    "id": "5LjeVgOZphCR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873032,
     "user_tz": -480,
     "elapsed": 52,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d8778dca-6916-44c2-cb9f-2f0f22528fe5",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.175499Z",
     "start_time": "2025-11-28T06:23:24.109175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在重新生成时间特征...\n",
      "Time_train shape: (6142, 6, 4)\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "还有其他一些静态数据,这些数据特点:不是时间序列,也就是训练一个样本需要一整个静态数据\n",
    "\n",
    "---\n",
    "\n",
    "为了简化实验,先只调入一个静态数据用作模型训练\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "上面以前的写的,现在用了全部数据"
   ],
   "metadata": {
    "id": "wiYBmpk9cFaC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "static_data_raw = file_dict['new_static_feat_f.npy']\n",
    "new_static_feat_f = torch.tensor(static_data_raw, dtype=torch.float32)\n",
    "\n",
    "print(f\"静态特征张量的形状: {new_static_feat_f.shape}\")"
   ],
   "metadata": {
    "id": "JUm3oOKxcR83",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873062,
     "user_tz": -480,
     "elapsed": 22,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "a0e8477c-dd60-458d-c77c-c486e382c64b",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.240377Z",
     "start_time": "2025-11-28T06:23:24.234236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "静态特征张量的形状: torch.Size([10, 10, 4])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "现在我们来导入其他文件\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "这四个文件不同于grid和static可作为Transformer的输入;它们是整个区域的地图只能通过模型内部 GCN 模块的连接矩阵\n",
    "\n",
    "---\n",
    "\n",
    "前三个是图,最后的grid_node能支持网格往返图  看它的格式是(100,63)\n",
    "\n",
    "\n",
    "---\n",
    "就是说我们本来是直接用static_feat的,现在我们用grid_node_map先转成图结构,然后与\n",
    "1. poi_adj_matrix\n",
    "2. road_adj_matrix\n",
    "3. risk_adj_matrix\n",
    "这三个文件融合,之后再通过grid_node_map转回网格结构,输入transformer\n"
   ],
   "metadata": {
    "id": "6STSxxQSq2uL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "poi_adj_matrix = file_dict['new_poi_adj_matrix_f.npy']\n",
    "road_adj_matrix = file_dict['new_road_adj_matrix_f.npy']\n",
    "risk_adj_matrix = file_dict['new_risk_adj_matrix_f.npy']\n",
    "grid_node_map = file_dict['new_grid_node_map_f.npy']\n",
    "\n",
    "adj_tensors = {\n",
    "    'poi': poi_adj_matrix,\n",
    "    'road': road_adj_matrix,\n",
    "    'risk': risk_adj_matrix,\n",
    "    'grid_node_map': grid_node_map\n",
    "}\n",
    "\n",
    "print(f\"POI邻接矩阵形状: {poi_adj_matrix.shape}\")\n",
    "print(f\"道路邻接矩阵形状: {road_adj_matrix.shape}\")\n",
    "print(f\"风险邻接矩阵形状: {risk_adj_matrix.shape}\")\n",
    "print(f\"网格节点映射形状: {grid_node_map.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gc1id4lfq420",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873137,
     "user_tz": -480,
     "elapsed": 75,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "c4621489-8532-44cd-ef1f-94bae76c1c37",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.349656Z",
     "start_time": "2025-11-28T06:23:24.339408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POI邻接矩阵形状: (63, 63)\n",
      "道路邻接矩阵形状: (63, 63)\n",
      "风险邻接矩阵形状: (63, 63)\n",
      "网格节点映射形状: (100, 63)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "用dataset继续创建数据集,不同于一般的x和y,这里还需要加上我们新创建的时间特征和静态特征\n",
    "\n",
    "---\n",
    "\n",
    "需要新写类,继承dataset,因为原dataset只支持两个参数"
   ],
   "metadata": {
    "id": "2nAiIeCg_Wob"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FullDataset(Dataset):\n",
    "    def __init__(self, X, Y, time_feature,static_data):\n",
    "        self.X = torch.tensor(X,dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y,dtype=torch.float32)\n",
    "        self.time_feature = torch.tensor(time_feature,dtype=torch.float32)\n",
    "\n",
    "        self.static_data = static_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.X[index], self.Y[index], self.time_feature[index],self.static_data  #共享就是体现在这里,没有[index],每个样本都需要完整的static\n",
    "        # 这样后在dataloader中拿static_data 格式就变成[B, 10 , 10, 4]"
   ],
   "metadata": {
    "id": "cHunjJoP_YBW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873138,
     "user_tz": -480,
     "elapsed": 15,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.459768Z",
     "start_time": "2025-11-28T06:23:24.443913Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "生成三个dataset"
   ],
   "metadata": {
    "id": "6BOggEieUxm8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = FullDataset(X_train, Y_train, Time_train,new_static_feat_f)\n",
    "val_dataset = FullDataset(X_valid, Y_valid, Time_val,new_static_feat_f)\n",
    "test_dataset = FullDataset(X_test, Y_test, Time_test,new_static_feat_f)"
   ],
   "metadata": {
    "id": "2JtTkqNwUtlw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873332,
     "user_tz": -480,
     "elapsed": 186,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.539299Z",
     "start_time": "2025-11-28T06:23:24.498921Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    " 开始dataloader"
   ],
   "metadata": {
    "id": "19lpslVDRh9L"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  #这里不会影响数据的时序性,滑动窗口切分（将连续的 history_steps 步作为 X）已经将每个样本（X, Y, Time）变成了独立的预测事件,所以打乱没影响\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)   #到时候写循环时,可以用for循环,一下子拿到多个数据\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ],
   "metadata": {
    "id": "wzritpMiRmVy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873425,
     "user_tz": -480,
     "elapsed": 86,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "0af05650-20cc-4d77-e5be-b68b78d9b727",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.573143Z",
     "start_time": "2025-11-28T06:23:24.562447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "41\n",
      "42\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型结构定义\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1.   将输入时空风险图 [B, history_steps, D, H, W] 转换成 Transformer 的 Tokens [B, Sequence_length, D_model] ----输入预处理\n",
    "\n",
    "> 用一个 2D 卷积操作同时完成了空间分块 (Patching) 和 特征投影 (Embedding)\n",
    "\n",
    "\n",
    "\n",
    "> 空间区域的数量视为序列的长度(Sequence_length) 这是最后的H/P和W/P\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "2.   还需要完成图卷积层(GCN) 实现将static信息转成图结构,用gcn将其与三个文件的结构信息融合,生成 增强后的静态特征 ($X_{\\text{static\\_GCN}}$)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "3.   ST-ViT 模型，用于时空风险预测\n",
    "\n",
    "\n",
    "> 引入了空间位置编码和时间位置编码,实际一张图我们分成了(Grid_size//Kernel_size)**2个小格子,每个小格子又有6个时间 所以一个序列的长度是互乘\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "EAUxuSbl8PYG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # 作为模型的子模块,用来处理 X_train (风险特征图)  使其符合transformer的输入格式\n",
    "# class PatchEmbedding(nn.Module):\n",
    "#     def __init__(self, d_model, D, history_steps, kernel_size):\n",
    "#         #d_model:transformer内部维度,也是我们要转换成的\n",
    "#         #D:风险特征的维度,也就是(6148, 7, 10, 10)中的7\n",
    "#         #history_steps:历史步信息,回过头看的信息\n",
    "#         #patch_size:分块大小\n",
    "\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Conv2d 的输入通道数是 D * history_steps\n",
    "\n",
    "#         # 重要:  这里因为考虑到卷积是只能看到Channels×H×W的图像,所以我们让风险特征维度和历史步推叠起来\n",
    "#         # 使得单次卷积能够看到所有历史和所有特征维度\n",
    "#         in_channels_conv = history_steps*D\n",
    "\n",
    "#         self.conv = nn.Conv2d(\n",
    "#             in_channels=in_channels_conv,\n",
    "#             out_channels=d_model,  # 输出通道数就是 D_model,转成transformer内部维度\n",
    "#             kernel_size=kernel_size,\n",
    "#             stride=kernel_size  #kernel_size和stride相同可以保证卷积不会重复\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):   #维度参考之前的处理 X_train shape: (6142, 6, 7, 10, 10)\n",
    "#         # 1. 调整维度(堆叠)：[B, history_steps, D, H, W] -> [B, history_steps*D, H, W]\n",
    "#         # transpose可有可无,习惯上让D优先于history_steps\n",
    "#         x = x.transpose(1, 2).flatten(1, 2)\n",
    "\n",
    "#         # 2. 卷积操作：[B, history_steps*D, H, W] -> [B, D_model, H/P, W/P]  这里实现把一张图进行分块\n",
    "#         x = self.conv(x)\n",
    "\n",
    "#         # 3. 展平和转置：[B, D_model, H/P, W/P] -> [B, Num_Patches, D_model]  得到序列长度,每一个小块是一个词,合起来就是一个序列\n",
    "#         # 这一步完成了 Token 的构建\n",
    "#         # x.flatten(2) 会展平从索引 2 开始到张量末尾的所有维度 让H/P和W/P相乘\n",
    "#         x = x.flatten(2).transpose(1, 2)\n",
    "#         return x"
   ],
   "metadata": {
    "id": "2SwZsnqK8VUa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873456,
     "user_tz": -480,
     "elapsed": 30,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.653746Z",
     "start_time": "2025-11-28T06:23:24.645978Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PatchEmbedding 应该独立处理每一个时间步，保留时间维度，让 Transformer 去做时序融合\n",
    "\n",
    "---\n",
    "\n",
    "上面的丢弃\n",
    "\n",
    "---\n",
    "\n",
    "旧逻辑： 把 $6$ 个时间步堆叠成通道，一次卷积全看完 $\\rightarrow$ 时间维度消失。新逻辑： 把 $6$ 个时间步视为 $6$ 张独立的图片，分别卷积 $\\rightarrow$ 保留时间维度 [B, T, N, D]。"
   ],
   "metadata": {
    "id": "61viSXYNiFR8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 在这里处理主输入\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, D, kernel_size): # 注意：这里去掉了 history_steps 参数\n",
    "        super().__init__()\n",
    "        # d_model: transformer内部维度\n",
    "        # D: 风险特征的维度 (7)\n",
    "        # kernel_size: 分块大小 (1)\n",
    "\n",
    "        # 输入通道数改为 D (7)，不再是 history_steps * D\n",
    "        # 我们要对每个时间步独立做卷积\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=D,\n",
    "            out_channels=d_model,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=kernel_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, history_steps, D, H, W]\n",
    "        B, T, D, H, W = x.shape\n",
    "\n",
    "        # 1. 合并 Batch 和 Time 维度，把每帧当做独立图片处理\n",
    "        # 原来是把TD融合,最后能通过view恢复时间维度,但是原来那样会把时间维度干消失掉\n",
    "        # [B, T, D, H, W] -> [B*T, D, H, W]\n",
    "        x = x.view(B * T, D, H, W)\n",
    "\n",
    "        # 2. 卷积操作 (Patching + Embedding)\n",
    "        # [B*T, D, H, W] -> [B*T, d_model, H/P, W/P]\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # 3. 展平空间维度并转置，生成 Tokens\n",
    "        # [B*T, d_model, H/P, W/P] -> [B*T, d_model, Num_Patches] -> [B*T, Num_Patches, d_model]\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        # 4. 恢复 Batch 和 Time 维度\n",
    "        # [B*T, Num_Patches, d_model] -> [B, T, Num_Patches, d_model]\n",
    "        x = x.view(B, T, -1, x.shape[-1])\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "id": "zXJppr3WiLo-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873559,
     "user_tz": -480,
     "elapsed": 102,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.713143Z",
     "start_time": "2025-11-28T06:23:24.689627Z"
    }
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面解决四个静态信息融合(除去grid主输入和grid_node_map)"
   ],
   "metadata": {
    "id": "SisnRqVwOlms"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 定义图卷积层\n",
    "# 对图上的每个节点，聚合它所有邻居的特征信息，并将这些信息融入到该节点自己的特征中\n",
    "# 先把static的特征转成D_model,再与adj相乘  让四个信息融合\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):  #传进去的参数为了把static的特征维度变成D_model\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "    def forward(self, x, adj):     # 把batch中每一个样本去和adj矩阵相乘\n",
    "        # x: [节点数, 特征数] [63,4]\n",
    "        # adj: [节点数, 节点数] [63,63]\n",
    "\n",
    "        # 1. 把static从当前维度转成D_model  new_static=[63,64]\n",
    "        new_static = self.linear(x)\n",
    "\n",
    "        # 2. 矩阵乘法 (图卷积，即邻居聚合)  不用相加 这是图信号处理中 唯一的 正确方式，它将邻接矩阵 A 作为 信息聚合的滤波器，实现了对邻居特征的加权求和\n",
    "        # 相加就可以理解成都糅合在一起了,信息乱掉了  ; 注意区分adj3个文件是可以相加的,它们是固定信息\n",
    "        output = torch.matmul(adj, new_static)  #[63,64]\n",
    "        return output\n",
    "\n",
    "# 借助上面的GCN正式处理statci和adj\n",
    "# --- 修改代码块 3: GCN 增加归一化 ---\n",
    "\n",
    "class StaticContextGCN(nn.Module):\n",
    "    def __init__(self, grid_size, map_tensor, adj_tensors, static_input_dim, D_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "        self.grid_node_map = map_tensor\n",
    "\n",
    "        self.gcn_layer = GCNLayer(static_input_dim, D_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 1. 初始邻接矩阵相加  就是把4个文件中除了grid_node_map相加\n",
    "        raw_adj = (adj_tensors['poi'] + adj_tensors['road'] + adj_tensors['risk'])\n",
    "\n",
    "        # 2. 关键修改: 计算归一化的拉普拉斯矩阵 (D^-0.5 * A * D^-0.5)\n",
    "        # 这里能保证数值稳定,跟上面dataset取log差不多\n",
    "\n",
    "        self.norm_adj = self.calculate_laplacian(raw_adj)\n",
    "\n",
    "    def calculate_laplacian(self, adj):   # 这边目的是实现拉普拉斯\n",
    "        # 添加自环 (Self-loop)，防止除零并保留自身特征\n",
    "        adj = adj + torch.eye(adj.size(0), device=adj.device)\n",
    "        # 计算度矩阵 D\n",
    "        row_sum = adj.sum(1)\n",
    "        d_inv_sqrt = torch.pow(row_sum, -0.5)\n",
    "        d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = torch.diag(d_inv_sqrt)\n",
    "\n",
    "        # 对称归一化\n",
    "        return torch.matmul(torch.matmul(d_mat_inv_sqrt, adj), d_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "    def forward(self, x_static):\n",
    "        # x_static: [B, 10, 10, 4]\n",
    "        batch_size = x_static.size(0)\n",
    "\n",
    "        # 由于静态特征所有样本都一样，我们只算一次图卷积，然后广播\n",
    "        # 取第一个样本: [10, 10, 4] -> [100, 4]\n",
    "        flat_static = x_static[0].flatten(0, 1)\n",
    "\n",
    "        # 映射到图节点: [100, 4]转置 * [100, 63] -> [4, 63] ->转置-> [63, 4]  注意用transpose调整顺序,特征数量往后放\n",
    "        node_features = torch.matmul(flat_static.transpose(0, 1), self.grid_node_map).transpose(0, 1)\n",
    "\n",
    "        # GCN 运算\n",
    "        # [63, 4] * [63, 63] -> ... -> [63, D_model]  还是在图节点中\n",
    "        gcn_out = self.relu(self.gcn_layer(node_features, self.norm_adj))\n",
    "\n",
    "        # 映射回网格  目的就是63->100\n",
    "        # [63, D_model]转置 * [63, 100] -> [D_model, 100] -> [100, D_model]\n",
    "        grid_features = torch.matmul(gcn_out.transpose(0, 1), self.grid_node_map.transpose(0, 1)).transpose(0, 1)\n",
    "\n",
    "        # 扩展回 Batch 维度: [B, 100, D_model]  unsqueeze实现0号位有维度,repeat实现广播至批次数量\n",
    "        return grid_features.unsqueeze(0).repeat(batch_size, 1, 1)"
   ],
   "metadata": {
    "id": "y8ZEweRINrJu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873562,
     "user_tz": -480,
     "elapsed": 3,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.750274Z",
     "start_time": "2025-11-28T06:23:24.728114Z"
    }
   },
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "在STViT_FineGrained中实现上面所述功能的组装"
   ],
   "metadata": {
    "id": "Iqymn55TTksj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class STViT_FineGrained(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, D, history_steps, future_steps,\n",
    "                 grid_size, kernel_size, num_patches, time_feature_dim,\n",
    "                 static_feature_dim, adj_tensors):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. 修改：PatchEmbedding 不再需要 history_steps 参数\n",
    "        self.patch_embed = PatchEmbedding(d_model, D, kernel_size)\n",
    "\n",
    "        self.time_embed = nn.Linear(time_feature_dim, d_model)      # 时间特征 (4 -> 64)\n",
    "\n",
    "        # GCN 模块 (保持不变)\n",
    "        self.static_context_gcn = StaticContextGCN(\n",
    "            grid_size=grid_size,\n",
    "            map_tensor=adj_tensors['grid_node_map'],\n",
    "            adj_tensors={k: v for k, v in adj_tensors.items() if k != 'grid_node_map'},\n",
    "            static_input_dim=static_feature_dim,\n",
    "            D_model=d_model\n",
    "        )\n",
    "\n",
    "        # 参数保存一下\n",
    "        self.num_patches = num_patches\n",
    "        self.D = D\n",
    "        self.history_steps = history_steps\n",
    "        self.future_steps = future_steps\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        # 位置编码  transformer必须的,不同于上面的时间特征,这里是'单句话中各个词之间的顺序'\n",
    "        # 开头设置成1是用于广播\n",
    "        self.spatial_pos_embedding = nn.Parameter(torch.randn(1, num_patches, d_model))\n",
    "        self.temporal_pos_embedding = nn.Parameter(torch.randn(1, history_steps, d_model))\n",
    "\n",
    "        # Transformer每个层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,  # 一般来讲,transormer内部前馈网络的维度就是D_model*4\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        # 预测头\n",
    "        flat_input_dim = history_steps * num_patches * d_model\n",
    "        flat_output_dim = future_steps * D * grid_size**2\n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.Linear(flat_input_dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, flat_output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_grid, x_time, x_static):\n",
    "        batch_size = x_grid.size(0)\n",
    "\n",
    "        # 1. Patch Embedding  主要输入\n",
    "        # 输入: [B, T=6, D, H, W]\n",
    "        # 输出: [B, T=6, N=100, D_model=64] (已经包含时间维度)\n",
    "        patch_embed = self.patch_embed(x_grid)\n",
    "\n",
    "        # 2. 特征嵌入(时间特征)  统一度量衡\n",
    "        # 时间嵌入: x_time 是 [B, 6, 4]\n",
    "        # 输出: [B, 6, 64]\n",
    "        time_embed = self.time_embed(x_time)\n",
    "\n",
    "        # 静态 GCN: x_static 是 [B, 10, 10, 4]\n",
    "        # 输出: [B, 100, 64] (静态特征，没有时间维度)\n",
    "        gcn_static_tokens = self.static_context_gcn(x_static)\n",
    "\n",
    "        # 3. 序列构造与融合\n",
    "\n",
    "        # a. 主序列：[B, 6, 100, 64] -> [B, 600, 64]   100个格子,每个格子6个时间  所以总'词'数为600\n",
    "        # 我们直接展平 Time 和 Spatial 维度\n",
    "        sequence = patch_embed.flatten(1, 2)\n",
    "\n",
    "        # b. 上下文融合\n",
    "        # 格式都要搞成sequence[B, 600, 64]的样式以便相加\n",
    "        # 时间上下文: [B, 6, 64] -> [B, 6, 1, 64] -> 复制100次 -> [B, 6, 100, 64] -> [B, 600, 64]\n",
    "        # 将每个时间步的特征广播到该时间步的所有 Patch 上  切忌6直接repeat->600\n",
    "        time_context = time_embed.unsqueeze(2).repeat(1, 1, self.num_patches, 1).flatten(1, 2)\n",
    "\n",
    "        # 静态上下文: [B, 100, 64] -> [B, 1, 100, 64] -> 复制6次 -> [B, 6, 100, 64] -> [B, 600, 64]\n",
    "        # 将静态特征广播到所有时间步上\n",
    "        gcn_context = gcn_static_tokens.unsqueeze(1).repeat(1, self.history_steps, 1, 1).flatten(1, 2)\n",
    "\n",
    "        # 融合所有特征\n",
    "        sequence = sequence + time_context + gcn_context\n",
    "\n",
    "        # c. 位置编码融合\n",
    "        # 时间 PE: [1, 6, 64] -> repeat_interleave -> [1, 600, 64] (1,1,..,1, 2,2,..,2)\n",
    "        # 注意时间要用repeat_interleave,因为不管是temp_pe还是spatial_pe都是以时间为主导的\n",
    "        temp_pe = self.temporal_pos_embedding.repeat_interleave(self.num_patches, dim=1)\n",
    "        # 空间 PE: [1, 100, 64] -> repeat -> [1, 600, 64] (1,2,..,100, 1,2,..,100)\n",
    "        spatial_pe = self.spatial_pos_embedding.repeat(1, self.history_steps, 1)\n",
    "\n",
    "        sequence = sequence + temp_pe + spatial_pe     # 所有数据处理完成\n",
    "\n",
    "        # --- 4. Transformer ---\n",
    "        transformer_output = self.transformer_encoder(sequence)    # [B,Sequence_length,D_model]\n",
    "\n",
    "        # --- 5. Prediction Head ---\n",
    "        flat_output = transformer_output.flatten(1)  # 展平后塞进全连接\n",
    "        pred = self.prediction_head(flat_output)\n",
    "\n",
    "        # 变成与Y相同的格式\n",
    "        pred = pred.view(batch_size, self.future_steps, self.D, self.grid_size, self.grid_size)\n",
    "        return pred"
   ],
   "metadata": {
    "id": "2_Cgo0ZLBA0-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873617,
     "user_tz": -480,
     "elapsed": 49,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.796555Z",
     "start_time": "2025-11-28T06:23:24.768475Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义模型运行在什么设备上"
   ],
   "metadata": {
    "id": "beB_lVVLV9rc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'当前模型运行在:{device}')"
   ],
   "metadata": {
    "id": "gHhRu8gWV_Wi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873625,
     "user_tz": -480,
     "elapsed": 11,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "cc27132f-1c32-4328-af03-a2a971f5794b",
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.826499Z",
     "start_time": "2025-11-28T06:23:24.820221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前模型运行在:cuda\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "把剩余的4个文件转移到gpu中\n",
    "提前传,不用等到训练中.这四个数据全局都在用"
   ],
   "metadata": {
    "id": "KsXMBxuZ0LxV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 用.float() 类型     这四个数据进去后全在乘\n",
    "poi_adj_matrix_tensor = torch.from_numpy(file_dict['new_poi_adj_matrix_f.npy']).float().to(device)\n",
    "road_adj_matrix_tensor = torch.from_numpy(file_dict['new_road_adj_matrix_f.npy']).float().to(device)\n",
    "risk_adj_matrix_tensor = torch.from_numpy(file_dict['new_risk_adj_matrix_f.npy']).float().to(device)\n",
    "\n",
    "# 2. 网格节点映射 一般用Long/Int\n",
    "# 修正：将其转换为 float 类型; 进去全在乘\n",
    "grid_node_map_tensor = torch.from_numpy(file_dict['new_grid_node_map_f.npy']).float().to(device) # 将 .long() 改为 .float()\n",
    "\n",
    "# 更新 adj_tensors 要让模型用tensor版本\n",
    "adj_tensors['poi'] = poi_adj_matrix_tensor\n",
    "adj_tensors['road'] = road_adj_matrix_tensor\n",
    "adj_tensors['risk'] = risk_adj_matrix_tensor\n",
    "adj_tensors['grid_node_map'] = grid_node_map_tensor"
   ],
   "metadata": {
    "id": "_LFVHZmI0JOG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873662,
     "user_tz": -480,
     "elapsed": 27,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.922785Z",
     "start_time": "2025-11-28T06:23:24.908134Z"
    }
   },
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义超参数"
   ],
   "metadata": {
    "id": "hbf9-3ppcoaL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "D_model=64   #transformer内部的工作维度\n",
    "N_heads=8    #多头注意力\n",
    "N_layers=3   #Encoder层数  编码器重复几次\n",
    "# History_steps=6  #历史步长  这两部分在之前生成X_train...的时候就有了\n",
    "# Future_steps=1      #预测步长\n",
    "D=7          #风险维度\n",
    "Grid_size=10  #网格大小,长宽都是10\n",
    "Kernel_size = 1   # 补丁大小-卷积大小和步长大小\n",
    "Num_patchs=(Grid_size//Kernel_size)**2  #每张图有几个块\n",
    "Time_feature_dim=4  #时间特征维度\n",
    "Static_feature_dim=4  #静态特征维度"
   ],
   "metadata": {
    "id": "MCfWArNscqfo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307873681,
     "user_tz": -480,
     "elapsed": 18,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:24.960286Z",
     "start_time": "2025-11-28T06:23:24.942302Z"
    }
   },
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "实例化模型"
   ],
   "metadata": {
    "id": "Xj_FVvTip2tV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model=STViT_FineGrained(D_model,N_heads,N_layers,D,history_steps,future_steps,Grid_size,Kernel_size,Num_patchs,Time_feature_dim,Static_feature_dim,adj_tensors)\n",
    "model.to(device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y73saVN7qDLk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307874162,
     "user_tz": -480,
     "elapsed": 471,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "outputId": "c9b37993-d7fc-4457-85e6-1504541b0841",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:25.148331Z",
     "start_time": "2025-11-28T06:23:24.980932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STViT_FineGrained(\n",
       "  (patch_embed): PatchEmbedding(\n",
       "    (conv): Conv2d(7, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (time_embed): Linear(in_features=4, out_features=64, bias=True)\n",
       "  (static_context_gcn): StaticContextGCN(\n",
       "    (gcn_layer): GCNLayer(\n",
       "      (linear): Linear(in_features=4, out_features=64, bias=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction_head): Sequential(\n",
       "    (0): Linear(in_features=38400, out_features=256, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=256, out_features=700, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  损失函数与优化器\n",
    "\n",
    "**零膨胀**\n",
    "在交通数据中，90% 以上的网格在大部分时间都是**没有事故 (0)** 的。\n",
    "如果我们使用普通的 MSE 损失，模型会倾向于“偷懒”——全部预测为 0 就能得到很小的误差。\n",
    "\n",
    "**解决方案：加权 MSE (Weighted MSE)**\n",
    "我们自定义了损失函数，给**真实发生事故 (Target > 0)** 的样本赋予 **20倍** 的权重。\n",
    "* 这迫使模型必须关注那些稀疏但重要的“高风险区域”，而不是单纯追求平均误差最小。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "这真的很重要,不然根本预测不出来,acc全是0,🤮"
   ],
   "metadata": {
    "id": "YUL0LiJjbLFD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 修改位置：自定义加权损失函数 ---\n",
    "\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, non_zero_weight=10.0):\n",
    "        super().__init__()\n",
    "        self.non_zero_weight = non_zero_weight\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # 计算标准 MSE: (pred - target)^2\n",
    "        loss = (pred - target) ** 2\n",
    "\n",
    "        # 权重矩阵\n",
    "        # 如果 target > 0 (有事故)，权重设为 non_zero_weight (例如 10)\n",
    "        # 如果 target == 0 (无事故)，权重设为 1\n",
    "        weights = torch.ones_like(target)   # 创建好权重矩阵(全1),默认都是无事故\n",
    "        weights[target > 0] = self.non_zero_weight  #给事故点赋值\n",
    "\n",
    "        # 应用权重\n",
    "        weighted_loss = loss * weights\n",
    "\n",
    "        # 返回平均损失\n",
    "        return weighted_loss.mean()\n",
    "\n",
    "# 使模型关注稀疏的事故数据\n",
    "criterion = WeightedMSELoss(non_zero_weight=20.0) # 权重可以尝试 10 或 20\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# 学习率衰减策略 (Scheduler)  无所谓\n",
    "# 损失在patience个epoch内不再下降,就将lr×factor衰减\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ],
   "metadata": {
    "id": "-m3mfxkqwtD5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307877483,
     "user_tz": -480,
     "elapsed": 3309,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:25.265992Z",
     "start_time": "2025-11-28T06:23:25.200181Z"
    }
   },
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练和验证主循环"
   ],
   "metadata": {
    "id": "SxbcsaxQ5WkQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    tqdm_ob = tqdm(dataloader, desc=f\"Training\", leave=False)\n",
    "\n",
    "    for x_grid, y_target, x_time, x_static in tqdm_ob:\n",
    "        x_grid = x_grid.to(device)\n",
    "        y_target = y_target.to(device)\n",
    "        x_time = x_time.to(device)\n",
    "        x_static = x_static.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        output = model(x_grid, x_time, x_static)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(output, y_target)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # --- 关键修复：梯度裁剪 ---      确实很重要,不然练的时候💣了\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # 优化\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失\n",
    "        total_loss += loss.item() * x_grid.size(0)\n",
    "\n",
    "        tqdm_ob.set_postfix({'Batch Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)  # 返回的是整个的平均损失"
   ],
   "metadata": {
    "id": "nBOnduXY5bEp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307877515,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:25.350455Z",
     "start_time": "2025-11-28T06:23:25.309302Z"
    }
   },
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "验证集的指标用rmse和recall\n",
    "\n",
    "---\n",
    "\n",
    "1.  **回归指标 (RMSE)**：均方根误差。用于衡量预测数值的准确度（越低越好）。\n",
    "2.  **分类指标 (Recall@TopK)**：\n",
    "    * **逻辑**：我们不看具体的数值准不准，而是看模型能否把**真正会发生事故的区域**排在预测列表的前面。\n",
    "    * **Top 5% Recall**：如果我们向预测风险最高的 5% 的区域派遣警力，能覆盖多少真实的事故？（越高越好）。"
   ],
   "metadata": {
    "id": "0c-F05pnyeuh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 修改代码块 4: 验证时反归一化 ---\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, top_k=50):\n",
    "    model.eval()\n",
    "    total_weighted_loss = 0\n",
    "\n",
    "    # 存储所有批次的预测值和真实值，用于计算全局指标\n",
    "    all_preds_real = []\n",
    "    all_targets_real = []\n",
    "\n",
    "    tqdm_ob = tqdm(dataloader, desc=f\"Validating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_grid, y_target, x_time, x_static in tqdm_ob:\n",
    "            x_grid, y_target, x_time, x_static = x_grid.to(device), y_target.to(device), x_time.to(device), x_static.to(device)\n",
    "\n",
    "            output = model(x_grid, x_time, x_static)    # shape类似Y:(6142, 1, 7, 10, 10)\n",
    "\n",
    "            # 1. 计算加权 Loss\n",
    "            loss = criterion(output, y_target)\n",
    "            total_weighted_loss += loss.item() * x_grid.size(0)\n",
    "\n",
    "            # 2. 反归一化\n",
    "            real_pred = torch.expm1(output).detach()  # detach从计算图中“分离”张量，返回一个不需要梯度、不参与反向传播的新张量\n",
    "            real_target = torch.expm1(y_target).detach()\n",
    "            real_pred = torch.clamp(real_pred, min=0)       # clamp将张量中的值限制在指定范围内（这里是下限为 0，无上限）\n",
    "\n",
    "            all_preds_real.append(real_pred)\n",
    "            all_targets_real.append(real_target)\n",
    "\n",
    "    # 合并所有 batch 数据 [Total_Samples, T, D, H, W]    拼接起来成一起\n",
    "    all_preds_real = torch.cat(all_preds_real, dim=0)\n",
    "    all_targets_real = torch.cat(all_targets_real, dim=0)\n",
    "\n",
    "    # --- 指标计算 1: RMSE (与论文对比) ---\n",
    "    mse = torch.mean((all_preds_real - all_targets_real) ** 2)\n",
    "    rmse = torch.sqrt(mse).item()\n",
    "\n",
    "    # --- 指标计算 2: Recall@K (论文标准) ---\n",
    "    # 将所有时空格子的预测值展平 [Total_Samples * T * D * H * W]      转成1维的好运算\n",
    "    flat_preds = all_preds_real.view(-1)\n",
    "    flat_targets = all_targets_real.view(-1)\n",
    "\n",
    "    # 求出总事故数\n",
    "    total_accidents = (flat_targets > 0).sum().item()\n",
    "\n",
    "    if total_accidents == 0:\n",
    "        recall_k = 0.0\n",
    "    else:\n",
    "        # 取预测值最高的 Top-K 个格子的索引\n",
    "        # 注意：这里 K 通常取总格子数的一定比例，或者固定数值(如前500个高风险点)\n",
    "        # 为了演示，我们取前 5% 的高风险格子作为 \"预测有事故\"\n",
    "        k_count = int(flat_preds.numel() * 0.05)   # 知道5%有多少格子\n",
    "        _, top_k_indices = torch.topk(flat_preds, k_count)   # 根据模型预测的风险值（flat_preds）从大到小排序，取出前 500 名的索引（位置 ID）。这些就是我们要派警察去的地方\n",
    "\n",
    "        # 看看这 Top-K 个预测中，有多少是真的发生了事故\n",
    "        hits = (flat_targets[top_k_indices] > 0).sum().item()\n",
    "\n",
    "        # Recall@K = 命中的事故数 / 总事故数\n",
    "        # 昨晚全城发生的事故中，有多少是被我们提前预测到并覆盖住的\n",
    "        recall_k = hits / total_accidents\n",
    "\n",
    "    # --- 指标计算 3: MAP (Mean Average Precision) ---\n",
    "    y_true = (flat_targets > 0).cpu().numpy().astype(int)\n",
    "    y_scores = flat_preds.cpu().numpy()\n",
    "\n",
    "    # 计算 MAP\n",
    "    # average_precision_score 本质上就是计算 AP\n",
    "    # 这里的 y_scores 不需要自己手动排序，sklearn 会自动排\n",
    "    map_score = average_precision_score(y_true, y_scores)\n",
    "\n",
    "    print(f\"MAP (平均精度均值): {map_score:.4f} (论文目标: ~0.0980)\")\n",
    "\n",
    "    avg_weighted_loss = total_weighted_loss / len(dataloader.dataset)\n",
    "\n",
    "    print(f\"\\n[论文同款指标]\")\n",
    "    print(f\"RMSE (均方根误差): {rmse:.4f} (论文目标: ~7.0353)\")\n",
    "    print(f\"Recall@Top5% : {recall_k*100:.2f}% (论文目标: ~21.95%)\")\n",
    "\n",
    "    return avg_weighted_loss, rmse, recall_k , map_score"
   ],
   "metadata": {
    "id": "vFARCWbjffi1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1764307877542,
     "user_tz": -480,
     "elapsed": 22,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-11-28T06:23:25.410706Z",
     "start_time": "2025-11-28T06:23:25.373578Z"
    }
   },
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练训练集,看看在验证集上如何"
   ],
   "metadata": {
    "id": "mjk3wAtB837I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epoches = 30\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    print('---------------------------------------------')\n",
    "    print(f'这是第 {epoch+1}/{epoches} 轮')\n",
    "\n",
    "    # --- 训练 ---\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "\n",
    "    # --- 验证 (设定阈值为 0.05) ---\n",
    "    # 注意：这里接收了 3 个返回值\n",
    "    val_loss, val_rmse, val_recall_k , val_map_score= validate_epoch(model, val_loader, criterion)\n",
    "\n",
    "    # --- 更新学习率 ---\n",
    "    # 基于 Validation Loss 调整学习率\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 手动打印当前学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Current Learning Rate: {current_lr}')\n",
    "\n",
    "    # --- 打印结果 ---\n",
    "    print(f'Train Weighted Loss: {train_loss:.4f}')\n",
    "    print(f'Val Weighted Loss:   {val_loss:.4f}')\n",
    "    print(f'Val RMSE:            {val_rmse:.4f}') # 关注这个\n",
    "    print(f'Val Recall@K:        {val_recall_k:.4f}') # 关注这个\n",
    "    print(f'Val MAP:             {val_map_score:.4f}') # 关注这个\n",
    "\n",
    "    print('---------------------------------------------')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457,
     "referenced_widgets": [
      "9c594ceee89344b08808b0a95053bbe0",
      "b304cb4e51d947dd8f95c6d4af58cd0f",
      "fe16232d3bc04b30879df38137aa82ef",
      "81b75029ed0f4223b39560509b0c9e5b",
      "ab77aa2eda3d4f9cbcc7bccb519a8ca0",
      "09df7e38e9aa4915a670c17784949d25",
      "7dc623b9fd974276b550fe9a8cb73806",
      "0a45f806bcdc4e9bae7ff1b4f35654a6",
      "27aec15769ce41d2a5a5cb2aacbafd77",
      "e155f5c7fb624ee2a91268e95738ab0d",
      "1367c0e190494c37a306d1883077576b"
     ]
    },
    "id": "qyX-2xHB85l4",
    "outputId": "01a19581-268b-494e-8856-4cf9848abf15",
    "executionInfo": {
     "status": "error",
     "timestamp": 1764307975522,
     "user_tz": -480,
     "elapsed": 97967,
     "user": {
      "displayName": "李知恩",
      "userId": "14685049950329399290"
     }
    },
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-28T06:23:25.496047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "这是第 1/30 轮\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/192 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b35010ffaa44504902b861ca2e0422b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Validating:   0%|          | 0/41 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e333b4057994f568dd81aadcad2e20d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP (平均精度均值): 0.7337 (论文目标: ~0.0980)\n",
      "\n",
      "[论文同款指标]\n",
      "RMSE (均方根误差): 49.6098 (论文目标: ~7.0353)\n",
      "Recall@Top5% : 28.75% (论文目标: ~21.95%)\n",
      "Current Learning Rate: 0.001\n",
      "Train Weighted Loss: 8.5494\n",
      "Val Weighted Loss:   0.9749\n",
      "Val RMSE:            49.6098\n",
      "Val Recall@K:        0.2875\n",
      "Val MAP:             0.7337\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "这是第 2/30 轮\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/192 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f28190bdc50743cca3d64182baa0493d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Validating:   0%|          | 0/41 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e34e4a2a6ebe408e9532acd8341570e0"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP (平均精度均值): 0.8059 (论文目标: ~0.0980)\n",
      "\n",
      "[论文同款指标]\n",
      "RMSE (均方根误差): 36.3457 (论文目标: ~7.0353)\n",
      "Recall@Top5% : 31.79% (论文目标: ~21.95%)\n",
      "Current Learning Rate: 0.001\n",
      "Train Weighted Loss: 1.3794\n",
      "Val Weighted Loss:   0.7117\n",
      "Val RMSE:            36.3457\n",
      "Val Recall@K:        0.3179\n",
      "Val MAP:             0.8059\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "这是第 3/30 轮\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/192 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f145defcaf44ba998dc469857bcf3b7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "可恶,这里recall竟然比论文还高,怎么可能呢?\n",
    "看到rmse偏高,所以可以认为模型在大惊小怪 倾向于在所有可能发生事故的危险区域（比如市中心路口）都预测极高的风险值"
   ],
   "metadata": {
    "id": "OMkKfNKHo_y7"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "9c594ceee89344b08808b0a95053bbe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b304cb4e51d947dd8f95c6d4af58cd0f",
       "IPY_MODEL_fe16232d3bc04b30879df38137aa82ef",
       "IPY_MODEL_81b75029ed0f4223b39560509b0c9e5b"
      ],
      "layout": "IPY_MODEL_ab77aa2eda3d4f9cbcc7bccb519a8ca0"
     }
    },
    "b304cb4e51d947dd8f95c6d4af58cd0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09df7e38e9aa4915a670c17784949d25",
      "placeholder": "​",
      "style": "IPY_MODEL_7dc623b9fd974276b550fe9a8cb73806",
      "value": "Training:   3%"
     }
    },
    "fe16232d3bc04b30879df38137aa82ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a45f806bcdc4e9bae7ff1b4f35654a6",
      "max": 192,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_27aec15769ce41d2a5a5cb2aacbafd77",
      "value": 6
     }
    },
    "81b75029ed0f4223b39560509b0c9e5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e155f5c7fb624ee2a91268e95738ab0d",
      "placeholder": "​",
      "style": "IPY_MODEL_1367c0e190494c37a306d1883077576b",
      "value": " 6/192 [01:37&lt;45:13, 14.59s/it, Batch Loss=31.6094]"
     }
    },
    "ab77aa2eda3d4f9cbcc7bccb519a8ca0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09df7e38e9aa4915a670c17784949d25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dc623b9fd974276b550fe9a8cb73806": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a45f806bcdc4e9bae7ff1b4f35654a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27aec15769ce41d2a5a5cb2aacbafd77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e155f5c7fb624ee2a91268e95738ab0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1367c0e190494c37a306d1883077576b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
